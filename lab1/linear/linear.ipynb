{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7541dec0-676e-453d-8133-034fdb0d4ec4",
   "metadata": {},
   "source": [
    "# Part 2: Linear Regression\n",
    "\n",
    "\n",
    "In this part, we will be working with a dataset scraped by [Shubham Maurya](https://www.kaggle.com/mauryashubham/linear-regression-to-predict-market-value/data), which collects facts about players in the English Premier League as of 2017. His original goal was to establish if there was a relationship between a player's popularity and his market value, as estimated by transfermrkt.com.\n",
    "\n",
    "**Your goal is to fit a model able to predict a player's market value.**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The dataset\n",
    "\n",
    "The dataset contains the following information:\n",
    "| **Field**   |     **Description**      |  \n",
    "|-------------|-------------|\n",
    "| name   |  Name of the player |\n",
    "| club   |  Club of the player |\n",
    "| age    | Age of the player |\n",
    "|position| The usual position on the pitch\n",
    "|position_cat| 1 for attackers, 2 for midfielders, 3 for defenders, 4 for goalkeepers|\n",
    "|market_value| As on transfermrkt.com on July 20th, 2017|\n",
    "|page_views| Average daily Wikipedia page views from September 1, 2016 to May 1, 2017|\n",
    "|fpl_value| Value in Fantasy Premier League as on July 20th, 2017|\n",
    "|fpl_sel| % of FPL players who have selected that player in their team|\n",
    "|fpl_points| FPL points accumulated over the previous season|\n",
    "|region| 1 for England, 2 for EU, 3 for Americas, 4 for Rest of World|\n",
    "|nationality| Player's nationality|\n",
    "|new_foreign| Whether a new signing from a different league, for 2017/18 (till 20th July)|\n",
    "|age_cat| a categorical version of the Age feature|\n",
    "|club_id| a numerical version of the Club feature|\n",
    "|big_club| Whether one of the Top 6 clubs|\n",
    "|new_signing| Whether a new signing for 2017/18 (till 20th July)|"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "572713cddf591afd"
  },
  {
   "cell_type": "markdown",
   "id": "ad7487f9-e685-4b2e-a215-7e6eabdec94a",
   "metadata": {},
   "source": [
    "## Exercise 1: Exploring the data\n",
    "The first step you need to do is to explore your data.\n",
    "\n",
    "We will start wil the necessary imports. In this exercise, we will be working with the library `pandas`. If you are not familiar with it, it is recommended that you follow the introductory exercises that can be found in the course's github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f34a7653-e8ac-4644-8421-cfe8bc2a3123",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:12:42.004123900Z",
     "start_time": "2023-10-27T14:12:41.812233600Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c16bb16-66ed-421c-a97a-d949b94aef29",
   "metadata": {},
   "source": [
    "We will now proceed to read the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b7b303c-61f7-4a0d-babc-dc830b6251b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:12:42.113489200Z",
     "start_time": "2023-10-27T14:12:41.824271800Z"
    }
   },
   "outputs": [],
   "source": [
    "league_df = pd.read_csv('data/football_data.csv') #Reads a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523a70e-af15-4766-9d65-d01758ca9146",
   "metadata": {},
   "source": [
    "### Task 1.1: Using pandas for data exploration\n",
    "Use the method `name_dataframe.head(N)` (N is the number of entries) to look at the first instances of the dataframe. \n",
    "\n",
    "Then, use the method `name_dataframe.describe(include='all')` to generate descriptive statistics that summarize each field of the dataframe. \n",
    "\n",
    "Finally, print the result of `name_dataframe.dtypes`, in this way you print out the data types associated to each of the fields in the table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d3c1a939-e6fc-410b-8110-90a844ba6882",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:12:42.144776300Z",
     "start_time": "2023-10-27T14:12:41.839941200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                name     club  age position  position_cat  market_value  \\\n0     Alexis Sanchez  Arsenal   28       LW             1          65.0   \n1         Mesut Ozil  Arsenal   28       AM             1          50.0   \n2          Petr Cech  Arsenal   35       GK             4           7.0   \n3       Theo Walcott  Arsenal   28       RW             1          20.0   \n4  Laurent Koscielny  Arsenal   31       CB             3          22.0   \n5    Hector Bellerin  Arsenal   22       RB             3          30.0   \n6     Olivier Giroud  Arsenal   30       CF             1          22.0   \n7      Nacho Monreal  Arsenal   31       LB             3          13.0   \n8   Shkodran Mustafi  Arsenal   25       CB             3          30.0   \n9         Alex Iwobi  Arsenal   21       LW             1          10.0   \n\n   page_views  fpl_value fpl_sel  fpl_points  region     nationality  \\\n0        4329       12.0  17.10%         264     3.0           Chile   \n1        4395        9.5   5.60%         167     2.0         Germany   \n2        1529        5.5   5.90%         134     2.0  Czech Republic   \n3        2393        7.5   1.50%         122     1.0         England   \n4         912        6.0   0.70%         121     2.0          France   \n5        1675        6.0  13.70%         119     2.0           Spain   \n6        2230        8.5   2.50%         116     2.0          France   \n7         555        5.5   4.70%         115     2.0           Spain   \n8        1877        5.5   4.00%          90     2.0         Germany   \n9        1812        5.5   1.00%          89     4.0         Nigeria   \n\n   new_foreign  age_cat  club_id  big_club  new_signing  \n0            0        4        1         1            0  \n1            0        4        1         1            0  \n2            0        6        1         1            0  \n3            0        4        1         1            0  \n4            0        4        1         1            0  \n5            0        2        1         1            0  \n6            0        4        1         1            0  \n7            0        4        1         1            0  \n8            0        3        1         1            1  \n9            0        1        1         1            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>club</th>\n      <th>age</th>\n      <th>position</th>\n      <th>position_cat</th>\n      <th>market_value</th>\n      <th>page_views</th>\n      <th>fpl_value</th>\n      <th>fpl_sel</th>\n      <th>fpl_points</th>\n      <th>region</th>\n      <th>nationality</th>\n      <th>new_foreign</th>\n      <th>age_cat</th>\n      <th>club_id</th>\n      <th>big_club</th>\n      <th>new_signing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alexis Sanchez</td>\n      <td>Arsenal</td>\n      <td>28</td>\n      <td>LW</td>\n      <td>1</td>\n      <td>65.0</td>\n      <td>4329</td>\n      <td>12.0</td>\n      <td>17.10%</td>\n      <td>264</td>\n      <td>3.0</td>\n      <td>Chile</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mesut Ozil</td>\n      <td>Arsenal</td>\n      <td>28</td>\n      <td>AM</td>\n      <td>1</td>\n      <td>50.0</td>\n      <td>4395</td>\n      <td>9.5</td>\n      <td>5.60%</td>\n      <td>167</td>\n      <td>2.0</td>\n      <td>Germany</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Petr Cech</td>\n      <td>Arsenal</td>\n      <td>35</td>\n      <td>GK</td>\n      <td>4</td>\n      <td>7.0</td>\n      <td>1529</td>\n      <td>5.5</td>\n      <td>5.90%</td>\n      <td>134</td>\n      <td>2.0</td>\n      <td>Czech Republic</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Theo Walcott</td>\n      <td>Arsenal</td>\n      <td>28</td>\n      <td>RW</td>\n      <td>1</td>\n      <td>20.0</td>\n      <td>2393</td>\n      <td>7.5</td>\n      <td>1.50%</td>\n      <td>122</td>\n      <td>1.0</td>\n      <td>England</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Laurent Koscielny</td>\n      <td>Arsenal</td>\n      <td>31</td>\n      <td>CB</td>\n      <td>3</td>\n      <td>22.0</td>\n      <td>912</td>\n      <td>6.0</td>\n      <td>0.70%</td>\n      <td>121</td>\n      <td>2.0</td>\n      <td>France</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Hector Bellerin</td>\n      <td>Arsenal</td>\n      <td>22</td>\n      <td>RB</td>\n      <td>3</td>\n      <td>30.0</td>\n      <td>1675</td>\n      <td>6.0</td>\n      <td>13.70%</td>\n      <td>119</td>\n      <td>2.0</td>\n      <td>Spain</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Olivier Giroud</td>\n      <td>Arsenal</td>\n      <td>30</td>\n      <td>CF</td>\n      <td>1</td>\n      <td>22.0</td>\n      <td>2230</td>\n      <td>8.5</td>\n      <td>2.50%</td>\n      <td>116</td>\n      <td>2.0</td>\n      <td>France</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Nacho Monreal</td>\n      <td>Arsenal</td>\n      <td>31</td>\n      <td>LB</td>\n      <td>3</td>\n      <td>13.0</td>\n      <td>555</td>\n      <td>5.5</td>\n      <td>4.70%</td>\n      <td>115</td>\n      <td>2.0</td>\n      <td>Spain</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Shkodran Mustafi</td>\n      <td>Arsenal</td>\n      <td>25</td>\n      <td>CB</td>\n      <td>3</td>\n      <td>30.0</td>\n      <td>1877</td>\n      <td>5.5</td>\n      <td>4.00%</td>\n      <td>90</td>\n      <td>2.0</td>\n      <td>Germany</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Alex Iwobi</td>\n      <td>Arsenal</td>\n      <td>21</td>\n      <td>LW</td>\n      <td>1</td>\n      <td>10.0</td>\n      <td>1812</td>\n      <td>5.5</td>\n      <td>1.00%</td>\n      <td>89</td>\n      <td>4.0</td>\n      <td>Nigeria</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code for head\n",
    "league_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "515dd667-c6a2-44b3-9faf-6110885f4c08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:12:42.144776300Z",
     "start_time": "2023-10-27T14:12:41.855529700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                  name     club         age position  position_cat  \\\ncount              461      461  461.000000      461    461.000000   \nunique             461       20         NaN       13           NaN   \ntop     Alexis Sanchez  Arsenal         NaN       CB           NaN   \nfreq                 1       28         NaN       85           NaN   \nmean               NaN      NaN   26.804772      NaN      2.180043   \nstd                NaN      NaN    3.961892      NaN      1.000061   \nmin                NaN      NaN   17.000000      NaN      1.000000   \n25%                NaN      NaN   24.000000      NaN      1.000000   \n50%                NaN      NaN   27.000000      NaN      2.000000   \n75%                NaN      NaN   30.000000      NaN      3.000000   \nmax                NaN      NaN   38.000000      NaN      4.000000   \n\n        market_value   page_views   fpl_value fpl_sel  fpl_points      region  \\\ncount     461.000000   461.000000  461.000000     461  461.000000  460.000000   \nunique           NaN          NaN         NaN     113         NaN         NaN   \ntop              NaN          NaN         NaN   0.10%         NaN         NaN   \nfreq             NaN          NaN         NaN      64         NaN         NaN   \nmean       11.012039   763.776573    5.447939     NaN   57.314534    1.993478   \nstd        12.257403   931.805757    1.346695     NaN   53.113811    0.957689   \nmin         0.050000     3.000000    4.000000     NaN    0.000000    1.000000   \n25%         3.000000   220.000000    4.500000     NaN    5.000000    1.000000   \n50%         7.000000   460.000000    5.000000     NaN   51.000000    2.000000   \n75%        15.000000   896.000000    5.500000     NaN   94.000000    2.000000   \nmax        75.000000  7664.000000   12.500000     NaN  264.000000    4.000000   \n\n       nationality  new_foreign     age_cat     club_id    big_club  \\\ncount          461   461.000000  461.000000  461.000000  461.000000   \nunique          61          NaN         NaN         NaN         NaN   \ntop        England          NaN         NaN         NaN         NaN   \nfreq           156          NaN         NaN         NaN         NaN   \nmean           NaN     0.034707    3.206074   10.334056    0.303688   \nstd            NaN     0.183236    1.279795    5.726475    0.460349   \nmin            NaN     0.000000    1.000000    1.000000    0.000000   \n25%            NaN     0.000000    2.000000    6.000000    0.000000   \n50%            NaN     0.000000    3.000000   10.000000    0.000000   \n75%            NaN     0.000000    4.000000   15.000000    1.000000   \nmax            NaN     1.000000    6.000000   20.000000    1.000000   \n\n        new_signing  \ncount    461.000000  \nunique          NaN  \ntop             NaN  \nfreq            NaN  \nmean       0.145336  \nstd        0.352822  \nmin        0.000000  \n25%        0.000000  \n50%        0.000000  \n75%        0.000000  \nmax        1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>club</th>\n      <th>age</th>\n      <th>position</th>\n      <th>position_cat</th>\n      <th>market_value</th>\n      <th>page_views</th>\n      <th>fpl_value</th>\n      <th>fpl_sel</th>\n      <th>fpl_points</th>\n      <th>region</th>\n      <th>nationality</th>\n      <th>new_foreign</th>\n      <th>age_cat</th>\n      <th>club_id</th>\n      <th>big_club</th>\n      <th>new_signing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>461</td>\n      <td>461</td>\n      <td>461.000000</td>\n      <td>461</td>\n      <td>461.000000</td>\n      <td>461.000000</td>\n      <td>461.000000</td>\n      <td>461.000000</td>\n      <td>461</td>\n      <td>461.000000</td>\n      <td>460.000000</td>\n      <td>461</td>\n      <td>461.000000</td>\n      <td>461.000000</td>\n      <td>461.000000</td>\n      <td>461.000000</td>\n      <td>461.000000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>461</td>\n      <td>20</td>\n      <td>NaN</td>\n      <td>13</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>113</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>61</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Alexis Sanchez</td>\n      <td>Arsenal</td>\n      <td>NaN</td>\n      <td>CB</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.10%</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>England</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>28</td>\n      <td>NaN</td>\n      <td>85</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>64</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>156</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>26.804772</td>\n      <td>NaN</td>\n      <td>2.180043</td>\n      <td>11.012039</td>\n      <td>763.776573</td>\n      <td>5.447939</td>\n      <td>NaN</td>\n      <td>57.314534</td>\n      <td>1.993478</td>\n      <td>NaN</td>\n      <td>0.034707</td>\n      <td>3.206074</td>\n      <td>10.334056</td>\n      <td>0.303688</td>\n      <td>0.145336</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.961892</td>\n      <td>NaN</td>\n      <td>1.000061</td>\n      <td>12.257403</td>\n      <td>931.805757</td>\n      <td>1.346695</td>\n      <td>NaN</td>\n      <td>53.113811</td>\n      <td>0.957689</td>\n      <td>NaN</td>\n      <td>0.183236</td>\n      <td>1.279795</td>\n      <td>5.726475</td>\n      <td>0.460349</td>\n      <td>0.352822</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>0.050000</td>\n      <td>3.000000</td>\n      <td>4.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>220.000000</td>\n      <td>4.500000</td>\n      <td>NaN</td>\n      <td>5.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>6.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>27.000000</td>\n      <td>NaN</td>\n      <td>2.000000</td>\n      <td>7.000000</td>\n      <td>460.000000</td>\n      <td>5.000000</td>\n      <td>NaN</td>\n      <td>51.000000</td>\n      <td>2.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>10.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>30.000000</td>\n      <td>NaN</td>\n      <td>3.000000</td>\n      <td>15.000000</td>\n      <td>896.000000</td>\n      <td>5.500000</td>\n      <td>NaN</td>\n      <td>94.000000</td>\n      <td>2.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>15.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>38.000000</td>\n      <td>NaN</td>\n      <td>4.000000</td>\n      <td>75.000000</td>\n      <td>7664.000000</td>\n      <td>12.500000</td>\n      <td>NaN</td>\n      <td>264.000000</td>\n      <td>4.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>6.000000</td>\n      <td>20.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code for describe\n",
    "league_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68f011b3-717d-4b64-87f2-9fc5eb7f8619",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:12:42.144776300Z",
     "start_time": "2023-10-27T14:12:41.902437Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "name             object\nclub             object\nage               int64\nposition         object\nposition_cat      int64\nmarket_value    float64\npage_views        int64\nfpl_value       float64\nfpl_sel          object\nfpl_points        int64\nregion          float64\nnationality      object\nnew_foreign       int64\nage_cat           int64\nclub_id           int64\nbig_club          int64\nnew_signing       int64\ndtype: object"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code for d_type\n",
    "league_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a406237-ec01-4643-83ce-53c2b740f809",
   "metadata": {},
   "source": [
    "### Question set 1.1: About the data\n",
    "1. What is the name of the appearing in the 7th record of the dataset? Olivier Giroud\n",
    "2. What is the mean age in the English Premier League (in 2017)? 26.804772\n",
    "3. What fields store a continuous value? market_value, fpl_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af0e869-6e8e-49f9-84c8-8813aa2fb8fa",
   "metadata": {},
   "source": [
    "Your answers here:\n",
    "1. Olivier Giroud\n",
    "2. 26.804772\n",
    "3. market_value, fpl_value, age, position_cat, page_views,fpl_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ab84d-f6d6-4ede-8b61-7b8fce77030a",
   "metadata": {},
   "source": [
    "## Exercise 2: Data splits, data preparation and training\n",
    "Before starting the training procedure, we need to split the data into the training, validation and test sets.\n",
    "\n",
    "In this exercise, the data will be already given split for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f4cd9aea-3abc-4616-b36d-916f012a7f2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:12:42.160401100Z",
     "start_time": "2023-10-27T14:12:41.918035600Z"
    }
   },
   "outputs": [],
   "source": [
    "#Loading the splits\n",
    "df_train = pd.read_csv('data/league_train.csv')\n",
    "df_val = pd.read_csv('data/league_val.csv')\n",
    "df_test = pd.read_csv('data/league_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef915478-b205-467d-a113-7546ce29d685",
   "metadata": {},
   "source": [
    "Alternatively, for the type of data used in this exercise, the library `scikit-learn` contains the function `train_test_split` that allows to automatically split the data.\n",
    "\n",
    "### Question set 2.1 Train_test_split\n",
    "Look at the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) of the `train_test_split` function:\n",
    "1. What parameters it receives as input? Provide examples illustrating.\n",
    "2. What is the role of the parameter shuffle?\n",
    "3. What is the role of the parameter test_size?\n",
    "4. The function does not generate a validation set. What would you do to obtain the desired data splits (train, validation and test)? Answer using pseudo-code (Bonus: Write the code for it so that it can run using some dummy generated data). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a70d65c-4813-4e3f-b155-620a2201fa0f",
   "metadata": {},
   "source": [
    "Your answers here:\n",
    "1. The parameters are the data to be split, the size of the test set, the size of the train set, the random state, the shuffle and the stratify.\n",
    "2. The shuffle parameter is used to shuffle the data before splitting it.\n",
    "3. The test_size parameter is used to determine the size of the test set, should be between 0.0 and 1.0 .\n",
    "4. I can use this function twice, first to split the data into train and test, and then to split the train data into train and validation.\n",
    "Bonus:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first\n",
      "x_train [ 8  5  2  1 11  4  7  3  6] x_test [10  9  0]\n",
      "y_train [1 1 0 0 1 1 1 0 1] y_test [1 1 0]\n",
      "Second\n",
      "x_train [0 1 2 3 4 5] x_test [ 6  7  8  9 10 11]\n",
      "y_train [0 0 0 0 1 1] y_test [1 1 1 1 1 1]\n",
      "Third\n",
      "x_train [ 1  3 11  4  7  9] x_test [ 0  5  6 10  2  8]\n",
      "y_train [0 0 1 1 1 1] y_test [0 1 1 1 0 1]\n",
      "BONUS\n",
      "[5 6 7 9 2 3] [8 1] [0 4]\n"
     ]
    }
   ],
   "source": [
    "# 1:\n",
    "# for the stratify parameter we created an example here, the first two doesn't use that parameter but we just show the difference between \"shuffle=true\" and \"shuffle=false\", while in the third example use the strafity which means that each of the two obtained sets contain the same % of samples of each class as the original set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "data=np.arange(12)\n",
    "label=np.array([0,0,0,0,1,1,1,1,1,1,1,1])\n",
    "X_train,X_test,y_train,y_test=train_test_split(data,label, test_size=0.2, random_state=42, shuffle=True, stratify=None)\n",
    "print(\"first\",)\n",
    "print(\"x_train\",X_train,\"x_test\",X_test)\n",
    "print(\"y_train\",y_train,\"y_test\",y_test)\n",
    "X_train,X_test,y_train,y_test=train_test_split(data,label, test_size=0.5, random_state=42, shuffle=False, stratify=None)\n",
    "print(\"Second\")\n",
    "print(\"x_train\",X_train,\"x_test\",X_test)\n",
    "print(\"y_train\",y_train,\"y_test\",y_test)\n",
    "X_train,X_test,y_train,y_test=train_test_split(data,label, test_size=0.5, random_state=42, shuffle=True, stratify=label)\n",
    "print(\"Third\")\n",
    "print(\"x_train\",X_train,\"x_test\",X_test)\n",
    "print(\"y_train\",y_train,\"y_test\",y_test)# we start with a 12 elements array with 8 \"1\" and 4 \"0\" and it is split with 2 sets of 6 elements (0.5) each one with 4 \"1\" and 2 \"0\" (stratify on the label)\n",
    "# BONUS:\n",
    "print(\"BONUS\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "data=np.arange(10)\n",
    "X,test=train_test_split(data, test_size=0.2, random_state=42)\n",
    "X,validation=train_test_split(X, test_size=0.25, random_state=42)\n",
    "print(X,test,validation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T14:12:42.160401100Z",
     "start_time": "2023-10-27T14:12:41.941612600Z"
    }
   },
   "id": "5ae5b54cb38bc999"
  },
  {
   "cell_type": "markdown",
   "id": "a107b65f-b24f-498a-9853-ea40fa932d88",
   "metadata": {},
   "source": [
    "The dataset contains a lot of features that can be used to build the model. We will start by using `age, fpl_value, big_club` and `page_views`.\n",
    "\n",
    "$$\\hat{y} = w_0 + w_1 x_{age} + w_2 x_{fplavalue} + w_3 x_{bigclub} + w_4(x_{pageviews})^{1/2}$$\n",
    "\n",
    "Before training the model, we need to prepare the data so that it can be used for training, validation and testing. The following steps need to be executed to prepare the data:\n",
    "\n",
    "1. Apply the np.sqrt( ) on the values of page_views\n",
    "2. Transform our variable in numpy array np.array(variable)\n",
    "3. Add a columns of ones to the matrix $\\mathbf{X}$  so it can handle the parameter $w_0$.\n",
    "\n",
    "### Task 2.1 Prepare data\n",
    "Complete the function `prepare_data(DataFrame)` where indicated so that all the steps listed above are performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "29378bc9-0709-476f-a79f-c8b9c0735794",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:12:42.175992300Z",
     "start_time": "2023-10-27T14:12:41.957274400Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def prepare_data(df):\n",
    "    '''\n",
    "        INPUT :\n",
    "        - df : a pandas DataFrame\n",
    "\n",
    "         OUTPUT :\n",
    "        - variable_array : The processed array\n",
    "    ''' \n",
    "    #We obtain a copy of the relevalnt fields from the DataFrame. This avoids modifying the dataframe directly. Instead, we work in a copy. Notice that we are not copying pageviews field\n",
    "    variable = df[['age', 'fpl_value', 'big_club']].copy()\n",
    "    \n",
    "    #Step 1.  Apply the np.sqrt( ) on the values of page_views\n",
    "    variable['sqrt_page_views'] = np.sqrt(df['page_views']) # YOUR CODE HERE\n",
    "    \n",
    "    # Step 2. Transform our variable in numpy array np.array(variable)\n",
    "    variable_array = np.array(variable)#YOUR CODE HERE\n",
    "    \n",
    "    # Step 3. Add a columns of ones to the matrix 𝐗 so it can handle the parameter 𝑤0.\n",
    "    # For this purpose we will use the function PolynomialFeatures from scikit-learn\n",
    "    variable_array = PolynomialFeatures(1).fit_transform(variable_array)\n",
    "    return variable_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c08aee-c052-47d7-b49b-c7a1f1b1ffd8",
   "metadata": {},
   "source": [
    "### Question set 2.2 PolynomialFeatures function\n",
    "Investigate the role of the [Polynomial features function](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) from scikit-learn. \n",
    "1. Why did the order of the polynomial was set to one in the prepare_data function? \n",
    "2. Given two features $x_1, x_2$, write down the expression that you would obtain by using the function by setting `degree=2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9509668-b80f-4fcf-bf8a-cd2f7d1b362f",
   "metadata": {},
   "source": [
    "Your answer here: \n",
    "1) Because if you set the order equal to 1 he will take all the features (grade=1) and 1 itself (grade=0) and will return the matrix.\n",
    "2) y=w0+w1*x1+w2*x2+w3*x1^2+w4*x1*x2+w5*x2^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8442bf4d-c6bf-4344-add4-156b023d1f28",
   "metadata": {},
   "source": [
    "Now, we execute the function to prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f6ba392a-3eb8-4101-b167-c0d872c9741a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:13:05.126077800Z",
     "start_time": "2023-10-27T14:13:05.080064400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         24.          4.5         1.         18.84144368]\n",
      " [ 1.         32.          7.5         0.         37.72267223]\n",
      " [ 1.         26.          5.5         0.         22.89104628]\n",
      " ...\n",
      " [ 1.         29.          6.5         0.         33.77869151]\n",
      " [ 1.         26.          7.5         1.         39.        ]\n",
      " [ 1.         23.          5.5         1.         17.23368794]]\n",
      "[[ 1.         24.          4.5         1.         18.84144368]\n",
      " [ 1.         32.          7.5         0.         37.72267223]\n",
      " [ 1.         26.          5.5         0.         22.89104628]\n",
      " ...\n",
      " [ 1.         29.          6.5         0.         33.77869151]\n",
      " [ 1.         26.          7.5         1.         39.        ]\n",
      " [ 1.         23.          5.5         1.         17.23368794]]\n",
      "[[ 1.         29.          5.          0.         23.40939982]\n",
      " [ 1.         22.          4.5         0.         18.86796226]\n",
      " [ 1.         20.          5.5         0.         14.83239697]\n",
      " [ 1.         30.          5.          0.         22.84731932]\n",
      " [ 1.         26.          4.5         0.          8.60232527]\n",
      " [ 1.         27.          5.          0.         35.665109  ]\n",
      " [ 1.         23.          5.          0.         26.81417536]\n",
      " [ 1.         25.          5.5         1.         35.4964787 ]\n",
      " [ 1.         30.          4.5         1.         31.591138  ]\n",
      " [ 1.         28.          6.5         0.         29.93325909]\n",
      " [ 1.         21.          4.5         1.         24.79919354]\n",
      " [ 1.         31.          4.          0.          9.38083152]\n",
      " [ 1.         31.          4.5         0.         16.21727474]\n",
      " [ 1.         20.          5.          1.         19.57038579]\n",
      " [ 1.         26.         10.          1.         47.45524207]\n",
      " [ 1.         23.          5.5         0.         22.71563338]\n",
      " [ 1.         27.          8.5         0.         29.3428015 ]\n",
      " [ 1.         30.          5.5         0.         22.44994432]\n",
      " [ 1.         25.          4.5         0.         16.91153453]\n",
      " [ 1.         27.          5.          0.         26.51414717]\n",
      " [ 1.         32.          5.          0.         26.41968963]\n",
      " [ 1.         33.          4.5         0.         13.49073756]\n",
      " [ 1.         36.          4.5         0.         14.6628783 ]\n",
      " [ 1.         29.          4.5         0.         12.92284798]\n",
      " [ 1.         19.          5.5         0.         37.2424489 ]\n",
      " [ 1.         29.          5.          0.         19.36491673]\n",
      " [ 1.         25.          5.          0.          8.06225775]\n",
      " [ 1.         31.          8.          1.         37.86819246]\n",
      " [ 1.         26.          7.          1.         32.24903099]\n",
      " [ 1.         26.         10.5         1.         64.96152708]\n",
      " [ 1.         28.          7.5         1.         45.33210783]\n",
      " [ 1.         32.          6.          0.         22.15851981]\n",
      " [ 1.         25.          4.5         0.         15.58845727]\n",
      " [ 1.         27.          5.          0.         12.40967365]\n",
      " [ 1.         27.          5.          0.         13.67479433]\n",
      " [ 1.         30.          5.          0.         14.73091986]\n",
      " [ 1.         25.          4.5         0.         18.54723699]\n",
      " [ 1.         28.          4.5         0.         10.77032961]\n",
      " [ 1.         23.          4.5         0.         14.07124728]\n",
      " [ 1.         25.          5.5         1.         41.94043395]\n",
      " [ 1.         24.          5.5         1.         19.89974874]\n",
      " [ 1.         20.          7.          1.         40.76763422]\n",
      " [ 1.         34.          4.5         0.         22.        ]\n",
      " [ 1.         27.          4.5         0.         15.23154621]\n",
      " [ 1.         27.          6.          0.         23.79075451]\n",
      " [ 1.         25.          4.5         0.         20.78460969]]\n",
      "[[ 1.         32.          5.5         0.         15.55634919]\n",
      " [ 1.         24.          4.5         0.          7.93725393]\n",
      " [ 1.         24.          6.          1.         21.30727575]\n",
      " [ 1.         27.          5.5         1.         35.15679166]\n",
      " [ 1.         28.          6.5         0.         29.563491  ]\n",
      " [ 1.         28.          6.          1.         27.49545417]\n",
      " [ 1.         31.          6.          1.         30.19933774]\n",
      " [ 1.         26.          5.          0.         17.49285568]\n",
      " [ 1.         22.          6.          1.         40.92676386]\n",
      " [ 1.         24.          4.          0.         10.67707825]\n",
      " [ 1.         27.          6.          0.         21.72556098]\n",
      " [ 1.         31.          6.5         1.         39.50949253]\n",
      " [ 1.         27.          4.5         0.         14.49137675]\n",
      " [ 1.         25.          9.          1.         33.42154993]\n",
      " [ 1.         27.          5.          0.         26.55183609]\n",
      " [ 1.         24.          6.          0.         22.97825059]\n",
      " [ 1.         22.          5.5         0.         20.39607805]\n",
      " [ 1.         23.          5.5         1.         30.82207001]\n",
      " [ 1.         34.          5.          0.         23.79075451]\n",
      " [ 1.         30.          4.5         0.         13.        ]\n",
      " [ 1.         27.          5.          0.         23.74868417]\n",
      " [ 1.         27.          4.5         0.          8.54400375]\n",
      " [ 1.         25.          9.          1.         54.38749856]\n",
      " [ 1.         27.          6.5         1.         29.12043956]\n",
      " [ 1.         32.          4.5         0.         12.92284798]\n",
      " [ 1.         30.          5.          0.         11.83215957]\n",
      " [ 1.         20.          4.5         0.          7.28010989]\n",
      " [ 1.         32.          5.5         0.         24.4744765 ]\n",
      " [ 1.         29.          5.5         0.         20.29778313]\n",
      " [ 1.         28.         10.          1.         66.73829485]\n",
      " [ 1.         20.          4.5         0.         16.97056275]\n",
      " [ 1.         26.          4.5         0.         11.22497216]\n",
      " [ 1.         25.          6.          0.         26.94438717]\n",
      " [ 1.         29.          7.          0.         39.7617907 ]\n",
      " [ 1.         21.          8.          1.         49.29503018]\n",
      " [ 1.         26.          5.5         1.         39.8246155 ]\n",
      " [ 1.         23.          5.          0.         15.77973384]\n",
      " [ 1.         22.          6.          0.          7.48331477]\n",
      " [ 1.         30.          5.5         1.         29.10326442]\n",
      " [ 1.         26.         10.5         1.         34.39476704]\n",
      " [ 1.         26.          5.          0.          1.73205081]\n",
      " [ 1.         32.          7.          1.         30.70830507]\n",
      " [ 1.         28.          9.5         1.         66.29479618]\n",
      " [ 1.         25.          5.          0.          9.32737905]\n",
      " [ 1.         27.          5.5         0.         22.86919325]\n",
      " [ 1.         26.          4.5         0.         15.32970972]\n",
      " [ 1.         26.          6.5         0.         36.7559519 ]\n",
      " [ 1.         20.          4.5         0.         11.22497216]\n",
      " [ 1.         30.          7.          1.         48.76474136]\n",
      " [ 1.         21.          4.5         0.         10.48808848]\n",
      " [ 1.         22.          7.5         1.         33.04542328]\n",
      " [ 1.         30.          4.5         0.         12.40967365]\n",
      " [ 1.         27.          5.5         0.         19.84943324]\n",
      " [ 1.         27.          4.5         0.         12.88409873]\n",
      " [ 1.         34.          4.5         0.         14.76482306]\n",
      " [ 1.         21.          4.5         0.         19.18332609]\n",
      " [ 1.         27.          4.5         0.         16.52271164]\n",
      " [ 1.         24.          5.          0.         20.90454496]\n",
      " [ 1.         28.          7.5         1.         48.91829923]\n",
      " [ 1.         28.          5.          0.         17.43559577]\n",
      " [ 1.         26.          5.          1.         23.49468025]\n",
      " [ 1.         26.          5.5         0.         33.19638535]\n",
      " [ 1.         24.          5.5         1.         42.60281681]\n",
      " [ 1.         33.          4.5         0.         25.47547841]\n",
      " [ 1.         25.          4.5         1.         23.68543856]\n",
      " [ 1.         34.          5.          1.         21.61018278]\n",
      " [ 1.         32.          4.5         1.         18.38477631]\n",
      " [ 1.         28.          5.          0.         21.86321111]\n",
      " [ 1.         19.          4.          1.         16.70329309]\n",
      " [ 1.         28.          6.5         0.         29.03446228]\n",
      " [ 1.         28.          5.          0.         11.5758369 ]\n",
      " [ 1.         24.          5.          0.         20.04993766]\n",
      " [ 1.         29.          5.5         0.         17.60681686]\n",
      " [ 1.         30.          5.          0.         15.90597372]\n",
      " [ 1.         24.          4.          0.          7.21110255]\n",
      " [ 1.         28.          4.5         0.          9.16515139]\n",
      " [ 1.         35.          4.5         0.         15.96871942]\n",
      " [ 1.         24.          4.5         0.         27.64054992]\n",
      " [ 1.         26.          4.5         0.         13.07669683]\n",
      " [ 1.         22.          4.5         0.         14.86606875]\n",
      " [ 1.         22.          5.5         1.         22.58317958]\n",
      " [ 1.         31.          5.          0.         21.47091055]\n",
      " [ 1.         27.          6.5         1.         31.74901573]\n",
      " [ 1.         23.          5.          1.         35.19943181]\n",
      " [ 1.         27.          5.          0.         13.56465997]\n",
      " [ 1.         21.          4.5         0.          3.        ]\n",
      " [ 1.         24.          7.          0.         22.20360331]\n",
      " [ 1.         33.          4.5         0.         13.07669683]\n",
      " [ 1.         28.          4.5         0.          8.66025404]\n",
      " [ 1.         31.          5.5         1.         23.55843798]\n",
      " [ 1.         26.          5.5         1.         22.91287847]\n",
      " [ 1.         27.          5.5         1.         40.03748244]\n",
      " [ 1.         25.          8.5         1.         46.86149806]]\n"
     ]
    }
   ],
   "source": [
    "#We copy the output label\n",
    "output_df_train=df_train['market_value'].copy()\n",
    "#We remove the output label from X\n",
    "input_df_train=df_train.drop(['market_value'],axis=1)\n",
    "\n",
    "#process is repeated for test and validation\n",
    "output_df_val=df_val['market_value'].copy()\n",
    "input_df_val=df_val.drop(['market_value'],axis=1)\n",
    "\n",
    "output_df_test=df_test['market_value'].copy()\n",
    "input_df_test=df_test.drop(['market_value'],axis=1)\n",
    "\n",
    "#We call prepare_data\n",
    "X_train = prepare_data(input_df_train)\n",
    "X_val = prepare_data(input_df_val)\n",
    "X_test = prepare_data(input_df_test)\n",
    "y_train = np.array(output_df_train)\n",
    "y_val = np.array(output_df_val)\n",
    "y_test = np.array(output_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8651c90-cf25-4808-aa42-281298c56503",
   "metadata": {},
   "source": [
    "We will now proceed to train our first model. In this case, we will use a \"home made\" implementation of linear regression. When dealing with more complex (and real) applications it is best to use the implementation that can be found in scikit-learn. \n",
    "\n",
    "We will define a class called my_linear_regression with four methods:\n",
    "1. `__init__(self)` : Constructor for the object to assign the object its properties\n",
    "2. `fit(self, X, y)` : Learning step of linear regression.\n",
    "3. `predict(self, X)` : predicts new labels $\\hat{y}$ given an input X\n",
    "4. `MSE(self,y_pred, y_test)` : Estimates the mean sum of squared errors between a set of predictions and the ground truth. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1026b99-7939-43ad-bbd3-c9ff992cfe4b",
   "metadata": {},
   "source": [
    "### Task 2.2 Mean sum of squared errors\n",
    "Implement the MSE function in the class below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "119e5e4a-f643-4420-9e4b-3ebc148a35d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:12:42.191641800Z",
     "start_time": "2023-10-27T14:12:42.004123900Z"
    }
   },
   "outputs": [],
   "source": [
    "class my_linear_regression:\n",
    "    def __init__(self) : # initialize constructor for the object to assign the object its properties\n",
    "        self.X_train = []\n",
    "        self.y_train = []\n",
    "        self.weights = []\n",
    "        \n",
    "    def fit(self, X, y) :\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.weights = np.linalg.solve(X.T@X,X.T@y)\n",
    "        # solves the matrix system equations\n",
    "    \n",
    "    def predict(self,x_test) : # method of the object that can be used\n",
    "        self.y_hat=np.sum(x_test*self.weights,axis=1)\n",
    "        \n",
    "        return self.y_hat\n",
    "    \n",
    "    def MSE(self,y_pred, y_test) :\n",
    "        #YOUR CODE HERE\n",
    "        MSE=np.sum((y_pred-y_test)**2)/len(y_pred)\n",
    "        #YOUR CODE ENDS HERE\n",
    "        return MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5120e9aa-0d4f-4097-b178-c6efdd2f8244",
   "metadata": {},
   "source": [
    "Now we can train our first model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c9ea396b-e75b-40f4-8980-06510d719f47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:12:42.191641800Z",
     "start_time": "2023-10-27T14:12:42.019778600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The learned model has parameters:\n",
      "[-15.66271385  -0.16641898   4.45892732   6.28285382   0.18420319]\n"
     ]
    }
   ],
   "source": [
    "model_1=my_linear_regression()\n",
    "model_1.fit(X_train,y_train)\n",
    "\n",
    "print(f'The learned model has parameters:\\n{model_1.weights}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf4b917-1d14-4d15-be62-6db8c010c9e6",
   "metadata": {},
   "source": [
    "### Question set 2.3: Interpreting the weights\n",
    "The estimated weights $\\mathbf{w}$ (excluding $w_0$) are associated to 'age', 'fpl_value', 'big_club' and 'page_views' (squared root), in that order. \n",
    "1. How do you interpret the values of each of these parameters? Based on this information, what can you say about the effect in a player's market value of his: age? number of page views? fpl value?\n",
    "Those are the weights for which we multiply each of our feature to obtain the prediction, so the higher the weight the more important is the feature in the prediction. So we can say that the big_club is the most important feature, followed by the fpl_value, the age and then the page views. The reason is that when we have 100 pages views and 100 years, we take the square root of the pages and then we multiply it with the weight while the age is multiplied directly with the weight.\n",
    "\n",
    "2. Which of these features seems to have the largest effect on a player's value? \n",
    "The big_club feature seems to have the largest effect on a player's value.\n",
    "\n",
    "3. How do you interpret the value obtained for $w_0$?\n",
    "The value of w0 is the value of the prediction when all the features are 0, so it is the offset of the line that represents the model that we use to perform regression. We use it because otherwise we constrain the line to pass through the origin and this is not always the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fa4974-67be-48c0-b88f-66e50234bf22",
   "metadata": {},
   "source": [
    "## Exercise 3: Adding categorical features\n",
    "It is well known that the position where a football player plays has an impact in his market value. Midfielders and stikers tend to be more expensive. Your goal now is to include this information in the model.\n",
    "\n",
    "As seen from the description, the player position is encoded as a numeric variable (1, 2, 3, 4). However, they represent categories and not values on their own. Categorical variables are commonly encoded under a scheme denoted 1-of-K encoding. This allows to convert a variable representing K different categories into K different binary values. Example:\n",
    "\n",
    "| **attacker**   |  **midfielder**      |  **defender** | **goalkeeper** |\n",
    "|-------------|-------------|-------------|-------------|\n",
    "| 1 | 0 | 0 | 0|\n",
    "| 0 | 1 | 0 | 0 |\n",
    "| 0 | 0 | 1 | 0 |\n",
    "| 0 | 0 | 0 | 1 | \n",
    "\n",
    "### Question 3.1: Adding the position to the model\n",
    "Write down the expression of the model if you consider the position of the player using 1-of-K encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527293ec-10be-465d-a93f-8d90d0e09fc9",
   "metadata": {},
   "source": [
    "Your answer here:\n",
    "given the 1-K= (attacker,midfielder,defender,goalkeeper)\n",
    "we can obtain the weight as: y=w0+w1*x1+w2*x2+w3*x3+w4*x4+w5*x5 where x5 is the 1-k encoding and w5 is a vector of weights corresponding to the weight of each possible categorical value (attacker,midfielder,defender,goalkeeper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82ec7a6-05f7-4d77-a219-3ae9b4f4586d",
   "metadata": {},
   "source": [
    "### Task 3.1 Preparing data with position features\n",
    "We need to modify the data preparation function so that it now includes the categorical features. For this matter, we have implemented the function `prepare_data_with_position(df)`. It contains the same functionality as the function `prepare_data(df)` and it adds the generation of the 1-of-K encoding. \n",
    "\n",
    "Complete the missing code in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "51d4e35c-44eb-423a-87fe-bf56f768e717",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:12:42.191641800Z",
     "start_time": "2023-10-27T14:12:42.035399100Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4233177447.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[76], line 3\u001B[1;36m\u001B[0m\n\u001B[1;33m    variable['sqrt_page_views'] =  #YOUR CODE HERE\u001B[0m\n\u001B[1;37m                                   ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def prepare_data_with_position(df):\n",
    "    variable = df[['age', 'fpl_value', 'big_club']].copy()\n",
    "    variable['sqrt_page_views'] =  #YOUR CODE HERE\n",
    "\n",
    "    variable=variable.join(pd.get_dummies(df.position_cat, prefix='pos')) # get_dummies to create 1-of-K encoding, join to add the new columns\n",
    "    variable_array = # YOUR CODE HERE\n",
    "    variable_array = PolynomialFeatures(1).fit_transform(variable_array)\n",
    "    \n",
    "    return variable_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497107d8-4e45-4a83-99b5-bf944f018f63",
   "metadata": {},
   "source": [
    "### Question 3.2 The get_dummies function\n",
    "Explain what the following line of code is doing:\n",
    "\n",
    "`variable=variable.join(pd.get_dummies(df.position_cat, prefix='pos'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa07407-83c6-41e4-a133-3fef4d3ad9df",
   "metadata": {},
   "source": [
    "### Task 3.2 Train the new model\n",
    "Your task now is to train the new model. For this you will need to execute the following steps: \n",
    "1. Prepare all your data (train, validation and testing). \n",
    "2. Create a new `my_linear_regression` object and store it in a variable named `model_2`\n",
    "3. Run the learning process\n",
    "4. For inspection purposes, print out the obtained weights.\n",
    "\n",
    "**Important:** While preparing the data, make sure you do not override the previous data used for model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a227776-fe52-4a4a-8a2b-52e3bbe65374",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-27T14:12:42.050989800Z"
    }
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ed5c8-116d-43fa-b522-9320fc49a791",
   "metadata": {},
   "source": [
    "### Question 3.3 Value of the position\n",
    "Based on the obtained weights, does it seem as if the position of the player has an important role in his market value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ae4a64-4ead-4822-8553-e42b0faad380",
   "metadata": {},
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a0f635-fd20-470f-9c71-404c09ceb068",
   "metadata": {},
   "source": [
    "## Exercise 4: Choosing a model\n",
    "We will now use the validation set to choose between the two models we have built so far. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3850c100-9372-4d42-879d-cdfd633171a9",
   "metadata": {},
   "source": [
    "### Task 4.1 MSE estimation\n",
    "Using the validation data, estimate the MSE for each of the two models that you have built so far. For this you will need to: \n",
    "1. Predict labels for the validation set using each of the trained models.\n",
    "2. Call the MSE function from any of the two models (it is equivalent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a22cf-fa48-40e7-b11f-04f7a05d0a3f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-27T14:12:42.050989800Z"
    }
   },
   "outputs": [],
   "source": [
    "#------------YOUR CODE HERE ------------\n",
    "\n",
    "#------------ YOUR CODE ENDS HERE ---------\n",
    "\n",
    "print(f'MSE model 1 :\\n{mse_1}\\n')\n",
    "print(f'MSE model 2 :\\n{mse_2}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e455b1f0-95d9-401b-921b-6fb18bb495aa",
   "metadata": {},
   "source": [
    "### Question set 4.1 Analysis\n",
    "1. Based on the obtained results, which model would you choose?\n",
    "2. Is the position feature useful to improve the model? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d42b5ff-f85e-4a70-8cae-606f2d675742",
   "metadata": {},
   "source": [
    "## Exercise 5: Model testing\n",
    "Use the test dataset to evaluate the generalization capabilities of the **model you chose** in the previous step. For this you need to:\n",
    "1. Predict the labels of the test set\n",
    "2. Estimate the MSE. Please note that other metrics, such as the RSS, could be used as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753114c5-80aa-4294-b4e2-10f4291a7fd4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-27T14:12:42.050989800Z"
    }
   },
   "outputs": [],
   "source": [
    "#------------YOUR CODE HERE ------------\n",
    "\n",
    "#------------ YOUR CODE ENDS HERE ---------\n",
    "\n",
    "print(f'MSE test:\\n{mse}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba9df6f-f37b-4204-89fe-4b140e983d16",
   "metadata": {},
   "source": [
    "### Question 5.1 Analysis\n",
    "Based on the previous result, what can you say about your model? Do you consider it makes sufficiently accurate predictions? Feel free to implement other metrics if you consider you need further information. Examples: RSS, Root Mean Squared Error or Mean Absolute Error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75323326-1b88-466e-b97f-e0346e5b8742",
   "metadata": {},
   "source": [
    "Your answer here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1721d943-d9b0-4816-8867-ddcae7544da9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-27T14:12:42.050989800Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
